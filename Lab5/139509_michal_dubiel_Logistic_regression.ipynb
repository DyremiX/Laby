{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie\n",
    "\n",
    "Przed rozpoczęciem pracy z notatnikiem proszę zmienić jego nazwę dodając na początku numer albumu, imię i nazwisko.\n",
    "{nr_albumu}\\_{imię}\\_{nazwisko}\\_{nazwa}\n",
    "\n",
    "Po wykonaniu wszystkich zadań proszę przesłać wypełniony notatnik przez platformę ELF za pomocą formularza \"Prześlij projekt\" w odpowiedniej sekcji. "
   ]
  },
  {
   "attachments": {
    "sigmoid.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna\n",
    "\n",
    "Perceptron bazujący na modelu sztucznego neuronu jest dobrym algorytmem, aby wyrobić sobie pewną intuicję, jednak nie jest on powszechnie stosowany do rozwiązywania problemów klasyfikacji. Głównym problemem jest wykorzystywana w nim funkcja aktywacji oraz, w konsekwencji, sposób uczenia. Funkcja skokowa Heaviside'a jest nieróżniczkowalna w punkcie $x=0$, a jej pochodna wynosi $0$ w każdym innym punkcie. Powoduje to, że metody gradientowe (w tym metoda gradientu prostego) nie mogą być stosowane do optymalizacji wag. Wiele algorytmów, w tym implementowana regresja liniowa, wykorzystuje metody gradientowe do optymalizacji. Aby to było możliwe w przypadku perceptronu, należy zmienić funkcję aktywacji na taką, która będzie różniczkowalna w każdym punkcie.\n",
    "\n",
    "### Funkcja sigmoidalna\n",
    "\n",
    "Funkcją, która spełnia powyższe wymagania jest funkcja sigmoidalna, zwana również funkcją logistyczną. Dana jest wzorem:\n",
    "\n",
    "$$f(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "Poniższy obraz przedstawia wykres funkcji sigmoidalnej.\n",
    "\n",
    "![sigmoid.png](attachment:sigmoid.png)\n",
    "\n",
    "Tak jak w przypadku funkcji skokowej Heaviside'a, funkcja mapuje dowolną wartość rzeczywistą na wartości z przedziału $(0,1)$. Wartość funkcji może być rozumiana jako prawdopodobieństwo wyniku pozytywnego. Przykładowo, jeśli $f(x) = 0.9$, to prawdopodobieństwo $1$ jest równe $90\\%$. Czyli jeśli mamy problem klasyfikacji binarnej, a $1$ oznacza np. obecność wirusa grypy w organiźmie, to możemy powiedzieć, że na $90\\%$ jesteśmy chorzy na grypę. Warto również zauważyć, że funkcja logistyczna zmierza do $1$ dla wartości dodatnich, a dla wartości ujemnych zmierza do $0$. Zmiana predykcji jest w punkcie $0$, gdzie wartość funkcji wynosi $0.5$.\n",
    "\n",
    "Zaletą funkcji sigmoidalnej jest łatwa do obliczenia pochodna:\n",
    "\n",
    "$$f(x)' = f(x)(1-f(x))$$\n",
    "\n",
    "Algorytm, który wykorzystuje tę funkcję aktywacji nazywany jest **regresją logistyczną**. Nazwa może być myląca i może sugerować, że służy on do rozwiązywania problemów regresji, ale w rzeczywistości wykorzystywany jest do problemów klasyfikacji.\n",
    "\n",
    "Finalnie, nasza hipoteza będzie wyglądać następująco.\n",
    "\n",
    "$$h_w(x) = f(\\sum_{i=0}^{n}{w_ix_i})$$\n",
    "\n",
    "$$s = \\sum_{i=0}^{n}{w_ix_i}$$\n",
    "\n",
    "$$f(s) = \\frac{1}{1+e^{-s}}$$\n",
    "\n",
    "### Funkcja błędu\n",
    "\n",
    "Poznaliśmy już jedną funkcję błędu, która wykorzystywana była do obliczenia błędu regresji liniowej (i wielomianowej). W przypadku regresji logistycznej nie możemy z niej skorzystać, ponieważ regresja logistyczna spowoduje, że taka funkcja będzie miała wiele lokalnych minimum, a co za tym idzie, znalezienie optymalnego zestawu wag będzie bardzo trudne. W związku z tym, konieczne jest znalezienie innej funkcji błędu. Powszechna funkcja błędu, która jest wykorzystywana w algorytmie regresji logistycznej ma następującą formę.\n",
    "\n",
    "$$\n",
    "Cost(h_w(x), y) =\n",
    "\\begin{cases}\n",
    "-log(h_w(x))        &   \\mathrm{if} \\ y=1,\\\\\n",
    "-log(1 - h_w(x))    &   \\mathrm{if} \\ y=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Gdzie $y$ jest prawdziwą wartością.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"attachment:cost1.png\" alt=\"Drawing\" style=\"\"/> </td>\n",
    "        <td> <img src=\"attachment:cost0.png\" alt=\"Drawing\" style=\"\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Czyli jeśli $y=0$, to funkcja kosztu będzie mieć wartość $0$, tylko jeśli hipoteza będzie mieć wartość $0$. Jeśli $h_w(x)$ zmierza do $1$, to funkcja kosztu zmierza do nieskończoności. \n",
    "\n",
    "Analogicznie, jeśli $y=1$, to funkcja kosztu będzie równa $0$ tylko, gdy hipoteza będzie równa $1$. Jeśli $h_w(x)$ będzie zmierzać do $0$, to wartość funkcji kosztu będzie zmierzać do nieskończoności.\n",
    "\n",
    "Zapis powyższej funkcji błędu może zostać uproszczony do jednego równania:\n",
    "\n",
    "$$Cost(h_w(x), y) = -y\\:log(h_w(x)) - (1 - y)\\:log(1 - h_w(x))$$\n",
    "\n",
    "Dlaczego można tak zrobić? Zauważmy, że jeśli $y=0$, to pierwsza część równania się zeruje, zostaje jedynie druga. Natomiast jeśli $y=1$, to zeruje się druga część równania, zostawiając jedynie pierwszą.\n",
    "\n",
    "### Trenowanie modelu\n",
    "\n",
    "Wzór na funkcję błędu dla regresji logistycznej można zapisać jako:\n",
    "\n",
    "$$J(w) = \\frac{1}{m} \\sum_{i=1}^{m}Cost(h_w(x^{(i)}),y^{(i)}) = - \\frac{1}{m} [\\sum_{i=1}^{m} y^{(i)} log(h_w(x^{(i)})) + (1 - y^{(i)}) log(1 - h_w(x^{(i)}))]$$\n",
    "\n",
    "Dobór wag przeprowadzony zostanie z wykorzystaniem algorytmu gradientu prostego. Tak jak w przypadku algorytmu regresji liniowej, w każdej epoce obliczone zostaną nowe wagi, które powinny skutkować zmniejszeniem błędu. W algorytmie perceptronu wagi akutalizowane były po każdej próbce uczącej, natomiast tutaj po jednym przejściu zestawu uczącego. Istnieją różne warianty ilości próbek, po których wagi są aktualizowane, jednak dla uproszczenia wybieramy cały zbiór.\n",
    "\n",
    "Dobra wiadomość jest taka, że proces aktualizacji wag wygląda praktycznie identycznie, jak miało to miejsce w przypadku algorytmu regresji liniowej. Pochodna funkcji błędu dla $j$-tej wagi ma postać: \n",
    "\n",
    "$$\\frac{\\partial J(w)}{\\partial w_j} = \\frac{1}{m} \\sum^{m}_{i=1} (h_w(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$\n",
    "\n",
    "Zatem wagi akutalizujemy tak, jak robiliśmy to uprzednio:\n",
    "\n",
    "$$w_j = w_j - \\alpha \\frac{\\partial J(w)}{\\partial w_j} = w_j - \\frac{\\alpha}{m} \\sum^{m}_{i=1} (h_w(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$\n",
    "\n",
    "Proces aktualizacji wag wynika bezpośrednio z obliczenia pochodnej funkcji błędu względem wag. W tym notatniku nie będziemy przechodzić przez cały ten proces. Dla osób, które chcą poznać matematyczne detale, przekształcenia opisane są np. [tutaj](https://towardsdatascience.com/logistic-regression-from-scratch-69db4f587e17).\n",
    "\n",
    "_Powyższy zapis jest w formie iteracyjnej, a w notaniku z regresją liniową był w formie macierzowej. Te dwa zapisy są równoznaczne i warto znać i rozumieć obie formy._\n",
    "\n",
    "### Regresja logistyczna a perceptron\n",
    "\n",
    "Powyższy algorytm w formie z sigmoidalną funkcją aktywacji bardzo często wykorzystywany jest jako podstawowy element wielowarstwowych sieci neuronowych. Jego dobre zrozumienie znacznie ułatwi zrozumienie sposobu działania sieci neuronowych. Porównując ze sobą działania algorytmu regresji logistycznej, a wcześniej implementowanego perceptronu, na pojedynczych neuronach nie widać róznic. Obie implementacje służą do rozwiązywania problemów klasyfikacji w zbiorach liniowo separowalnych. Ich celem jest wyznaczenie prostej separującej próbki pochodzące z różnych klas. Różnica pojawia się w momencie, gdy chcemy stworzyć strukturę złożoną z wielu neuronów. Wykorzystanie w tym celu perceptronu nie jest możliwe, ponieważ sieci neuronowe trenowane są najcześciej z wykorzystaniem algorytmu opartego o obliczenie gradientu funkcji błędu.\n",
    "\n",
    "Struktury złożone z wielu neuronów mogą rozwiązywać problemy nieliniowo separowalne. Daje to duże możliwości i tłumaczy duże zainteresowanie sieciami neuronowymi. Innym sposobem na rozwiązanie problemu nieliniowo separowalnego może być rozwinięcie hipotezy o wielomianową formę, tak jak robiliśmy to w przypadku regresji wielomianowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n",
    "\n",
    "Zaimplementuj opisany algorytm regresji logistycznej, który będzie skutecznie klasyfikował próbki z liniowo separowalnego zestawu danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2\n",
    "\n",
    "Wczytaj zbiór danych znajdujący się w pliku Ankieta.csv, stwórz wykres próbek. Następnie stwórz 3 wykresy na których przedstawisz jak zmieniała się granica decyzyjna zaimplementowanego algorytmu regresji logistycznej na przestrzeni epok. Porównaj wynik z algorytmem perceptronu (zarówno czas działania jak i jakość wyznaczonej granicy decyzyjnej)\n",
    "\n",
    "**Uwaga:** Przed podaniem danych na wejście klasyfikatora należy je znormalizować. Zbyt duże wartości powodują, że logarytmy liczą się niepoprawnie (log(0) daje NaN). Dla zainteresowanych wyjaśnienie dostępne jest [tutaj](https://stackoverflow.com/questions/35419882/cost-function-in-logistic-regression-gives-nan-as-a-result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import random\n",
    "from typing import Tuple, List\n",
    "\n",
    "def initialize_coefficients(n: int = 2, alpha = None) -> Tuple[float, np.ndarray]:\n",
    "    #YOUR CODE HERE\n",
    "    return (random.random() if alpha == None else alpha,np.array([random.random() for x in range(n + 1)]))\n",
    "\n",
    "def calculate_regression_function(X: np.ndarray, betas: np.ndarray) -> np.ndarray:\n",
    "    #YOUR CODE HERE\n",
    "    result = []\n",
    "    for x in X:\n",
    "        suma = betas[0]\n",
    "        for i in range(len(x)):\n",
    "            suma += x[i] * betas[1:][i]\n",
    "        result.append(suma)\n",
    "    return np.array(result)\n",
    "    # return np.array([betas[0] + np.sum([a * beta for a,beta in zip(x,betas[1:])]) for x in X])\n",
    "\n",
    "def calculate_error(X: np.ndarray, y: np.ndarray, betas: np.ndarray) -> float:\n",
    "    #YOUR CODE HERE\n",
    "    results = calculate_regression_function(X,betas)\n",
    "    suma = 0\n",
    "    for i in range(len(results)):\n",
    "        suma += np.power((results[i] - y[i]),2)\n",
    "    return suma/(len(y)*2)\n",
    "    # return np.sum((calculate_regression_function(X,betas) - y)**2)/len(y)\n",
    "\n",
    "def calculate_gradient(X: np.ndarray, y: np.ndarray, betas: np.ndarray) -> np.ndarray:\n",
    "    #YOUR CODE HERE\n",
    "    results = calculate_regression_function(X,betas)\n",
    "    gradient = []\n",
    "    ### Obliczenie pierwszej bety\n",
    "    suma = 0\n",
    "    for i in range(len(results)):\n",
    "        suma += (results[i] - y[i])\n",
    "    gradient.append(suma/len(y))\n",
    "    ### Obliczenie reszty bety\n",
    "    for j in range(1,len(betas)):\n",
    "        sum = 0\n",
    "        for i in range(len(results)):\n",
    "            sum += (results[i] - y[i])*X[i][j-1]\n",
    "        gradient.append(sum/len(y))\n",
    "    return np.array(gradient)\n",
    "    # return np.append(np.array(np.sum(calculate_regression_function(X,betas) - y)/len(y)), \n",
    "    #                  np.array([np.sum([np.array(calculate_regression_function(X,betas) - y)*x[i] for x in X])/len(y) for i in range(len(betas[1:]))]))\n",
    "\n",
    "def update_regression_coefficients(X: np.ndarray, y: np.ndarray, betas: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    #YOUR CODE HERE\n",
    "    result = calculate_gradient(X,y,betas)\n",
    "    new_betas = []\n",
    "    for i in range(len(betas)):\n",
    "        new_betas.append(betas[i] - result[i]*alpha)\n",
    "    return np.array(new_betas)\n",
    "    # return np.array(betas-calculate_gradient(X,y,betas)*alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "\n",
    "Wykorzystaj stworzony algorym w celu znalezienia granicy decyzyjnej będącej płaszczyzną w trójwymiarowej przestrzeni. Zbiór danych znajduje się w pliku o nazwie 3D_perceptron.csv. Stwórz wykresy analogicznie jak w zadaniu 2. Porównaj wynik z algorytmem perceptronu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementu test jednostkowy sprawdzający czy błąd spada wraz z epokami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaproponuj i oblicz miarę skuteczności algorytmu regresji logistycznej. Wynik należy podać w % (ile próbek poprawnie zaklasyfikował algorytm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak współczynnik uczenia alpha wypływa na wynik oraz ilość epok jakie należy zastosować? Porównaj minimum 5 różnych wartości współczynnika alpha oraz sformułuj wnioski."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
